{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/saipragna25/deep-learning-assignment-2B-/blob/main/DLA2bPytorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "PYTORCH\n"
      ],
      "metadata": {
        "id": "_04gRVMaUsvv"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "x_O7EYmr7Zjk"
      },
      "outputs": [],
      "source": [
        "import torch\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Scalar vector multiplication\n",
        "\n",
        "a = torch.rand(1)\n",
        "b = torch.rand(4, 6)\n",
        "c = torch.einsum('i, ij -> ij', [a, b])\n",
        "print(a)\n",
        "print(b)\n",
        "print(c)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Y1LUGch7wgr",
        "outputId": "a318673c-1518-4408-b9e4-286998828bb0"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0.7342])\n",
            "tensor([[0.3294, 0.2023, 0.0293, 0.7053, 0.0873, 0.5140],\n",
            "        [0.9745, 0.2776, 0.2000, 0.8226, 0.2266, 0.8492],\n",
            "        [0.5204, 0.6569, 0.0837, 0.6028, 0.5085, 0.1036],\n",
            "        [0.9294, 0.9356, 0.4526, 0.3326, 0.1977, 0.8051]])\n",
            "tensor([[0.2419, 0.1485, 0.0215, 0.5179, 0.0641, 0.3774],\n",
            "        [0.7155, 0.2038, 0.1468, 0.6040, 0.1664, 0.6235],\n",
            "        [0.3821, 0.4823, 0.0615, 0.4426, 0.3734, 0.0760],\n",
            "        [0.6824, 0.6869, 0.3323, 0.2442, 0.1451, 0.5911]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Vector vector multiplication\n",
        "\n",
        "a = torch.rand(2, 4)\n",
        "b = torch.rand(4, 6)\n",
        "c= torch.einsum('ij, jk -> ik', [a, b])\n",
        "print(a)\n",
        "print(b)\n",
        "print(c)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TZ4CMTM_755g",
        "outputId": "df36a7c7-c740-44ef-adaa-6acb24f96063"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.5318, 0.8626, 0.3874, 0.1230],\n",
            "        [0.0476, 0.1583, 0.8002, 0.9898]])\n",
            "tensor([[0.6362, 0.5842, 0.1136, 0.1367, 0.0992, 0.6324],\n",
            "        [0.7461, 0.6953, 0.7746, 0.5065, 0.8117, 0.9511],\n",
            "        [0.4874, 0.9649, 0.1934, 0.1719, 0.8082, 0.0674],\n",
            "        [0.2992, 0.0246, 0.3222, 0.9294, 0.1101, 0.9374]])\n",
            "tensor([[1.2075, 1.2873, 0.8431, 0.6905, 1.0795, 1.2981],\n",
            "        [0.8345, 0.9343, 0.6018, 1.1442, 0.8889, 1.1624]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Outer product\n",
        "\n",
        "a = torch.arange(5)\n",
        "b = torch.arange(3, 6)  \n",
        "op= torch.einsum('i,j -> ij', [a, b])\n",
        "print(a)\n",
        "print(b)\n",
        "print(op)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x-49ddgB8Pnz",
        "outputId": "c2461f37-755a-40f7-8a03-8f4202285615"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0, 1, 2, 3, 4])\n",
            "tensor([3, 4, 5])\n",
            "tensor([[ 0,  0,  0],\n",
            "        [ 3,  4,  5],\n",
            "        [ 6,  8, 10],\n",
            "        [ 9, 12, 15],\n",
            "        [12, 16, 20]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Scalar dot product\n",
        "\n",
        "a = torch.arange(9).reshape(3, 3)\n",
        "b = torch.arange(6).reshape(3, 2)\n",
        "sp = torch.einsum('ij, jk ->', [a, b])\n",
        "print(a)\n",
        "print(b)\n",
        "print(sp)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3_ddVdB38UIJ",
        "outputId": "8461f729-f81c-4f10-bd70-58033ed8f122"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0, 1, 2],\n",
            "        [3, 4, 5],\n",
            "        [6, 7, 8]])\n",
            "tensor([[0, 1],\n",
            "        [2, 3],\n",
            "        [4, 5]])\n",
            "tensor(204)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Hadamard product\n",
        "\n",
        "a = torch.arange(8).reshape(2, 4)\n",
        "b = torch.arange(4, 12).reshape(2, 4)\n",
        "hp = torch.einsum('ij, ij -> ij', [a, b])\n",
        "print(a)\n",
        "print(b)\n",
        "print(hp)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TscM27338qr9",
        "outputId": "ba91cb70-ece5-4a44-9e77-01191fe87ab0"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0, 1, 2, 3],\n",
            "        [4, 5, 6, 7]])\n",
            "tensor([[ 4,  5,  6,  7],\n",
            "        [ 8,  9, 10, 11]])\n",
            "tensor([[ 0,  5, 12, 21],\n",
            "        [32, 45, 60, 77]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Batch matrix multiplication\n",
        "\n",
        "a = torch.randn(3, 3, 5)\n",
        "b = torch.randn(3, 5, 2)\n",
        "batch_matrix_mul = torch.einsum('bij, bjk -> bik', [a, b])\n",
        "print(a)\n",
        "print(b)\n",
        "print(batch_matrix_mul)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zgvmyiWD86Ck",
        "outputId": "7b28f857-4501-40e7-b5e6-bb8781ad69e5"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[-2.5184,  0.8463, -0.1660, -0.7315, -0.8490],\n",
            "         [ 1.4984,  1.0025,  1.6241, -0.4707, -0.8756],\n",
            "         [ 0.0591, -1.3159, -0.1089, -1.2147,  1.2578]],\n",
            "\n",
            "        [[ 0.8064,  0.9094, -0.0124,  2.4760, -1.5924],\n",
            "         [-0.9544,  1.2134, -0.1827,  0.3308,  0.2178],\n",
            "         [-0.6285,  0.7844, -0.5178,  2.2740, -0.2897]],\n",
            "\n",
            "        [[ 1.3131, -0.3015, -0.8730,  1.6285, -1.4950],\n",
            "         [ 1.1432,  1.0117, -1.3117,  0.3460,  0.0261],\n",
            "         [-1.8562,  0.6623, -0.6490, -0.0235,  1.1036]]])\n",
            "tensor([[[ 1.1617, -0.0744],\n",
            "         [-1.0282,  0.7458],\n",
            "         [ 0.1351,  0.4993],\n",
            "         [-0.1549, -0.7520],\n",
            "         [-0.7117, -0.6169]],\n",
            "\n",
            "        [[-1.0381, -0.8409],\n",
            "         [ 0.0165,  0.7990],\n",
            "         [ 0.2251, -0.0251],\n",
            "         [ 0.5351,  0.8074],\n",
            "         [ 0.3985,  0.4352]],\n",
            "\n",
            "        [[-0.6814,  1.0494],\n",
            "         [-0.1585,  2.1327],\n",
            "         [-0.7298,  0.2824],\n",
            "         [ 0.3727, -0.6336],\n",
            "         [-0.8802, -2.5468]]])\n",
            "tensor([[[-3.1007,  1.8095],\n",
            "         [ 1.6256,  2.3413],\n",
            "         [ 0.7000, -0.9027]],\n",
            "\n",
            "        [[-0.1346,  1.3550],\n",
            "         [ 1.2335,  2.1385],\n",
            "         [ 1.6503,  2.8782]],\n",
            "\n",
            "        [[ 1.7131,  3.2642],\n",
            "         [ 0.1240,  2.7010],\n",
            "         [ 0.6533, -3.5146]]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Tensor reduction\n",
        "\n",
        "a = torch.randn(2, 3, 5, 7)\n",
        "b = torch.randn(4, 1, 3, 11, 5)\n",
        "tensor_reduction = torch.einsum('pqrs, tuqvr -> pstuv', [a, b])\n",
        "print(a.shape, b.shape, tensor_reduction.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jPocnSCH8_fZ",
        "outputId": "067ce522-6502-4317-e644-e9966dabcef5"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([2, 3, 5, 7]) torch.Size([4, 1, 3, 11, 5]) torch.Size([2, 7, 4, 1, 11])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Transpose\n",
        "\n",
        "a = torch.arange(8).reshape(4, 2)\n",
        "transpose = torch.einsum('ij -> ji', [a])\n",
        "print(a)\n",
        "print(transpose)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "StmTS9VZ9Ce8",
        "outputId": "1b73f05e-8d1d-459d-efc4-b234003b1b79"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0, 1],\n",
            "        [2, 3],\n",
            "        [4, 5],\n",
            "        [6, 7]])\n",
            "tensor([[0, 2, 4, 6],\n",
            "        [1, 3, 5, 7]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Bilinear transformation\n",
        "\n",
        "a = torch.randn(2, 3)\n",
        "b = torch.randn(3, 3, 4)\n",
        "c = torch.randn(2, 4)\n",
        "bilinear_transform = torch.einsum('ik, jkl, il -> ij', [a, b, c])\n",
        "print(a)\n",
        "print(b)\n",
        "print(c)\n",
        "print(bilinear_transform)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jyQ27_eS9Fxt",
        "outputId": "e7f6a010-8ea1-4d85-da54-7104dd6e053c"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-0.2455, -0.3778,  1.5716],\n",
            "        [-1.1057,  0.9032,  0.5375]])\n",
            "tensor([[[-1.3603,  0.4806, -2.1497,  1.9873],\n",
            "         [-0.4892,  2.2299,  2.0188, -1.6711],\n",
            "         [ 0.6978,  2.4299,  0.0644, -0.8094]],\n",
            "\n",
            "        [[ 0.2159, -1.2592, -0.1304, -1.0520],\n",
            "         [-1.3401,  0.3318, -1.9800, -1.6966],\n",
            "         [-0.7593, -1.9865,  0.7129, -0.0871]],\n",
            "\n",
            "        [[-1.0283,  0.2825,  0.0713,  0.5208],\n",
            "         [-0.3179,  0.4338,  0.4392, -1.7319],\n",
            "         [-0.5855, -0.5687, -0.6299,  0.8627]]])\n",
            "tensor([[ 0.9253, -0.6718, -1.6440, -0.8909],\n",
            "        [-0.6574,  1.1717, -0.7898, -0.8136]])\n",
            "tensor([[ 0.7999, -2.5143,  0.5026],\n",
            "        [ 2.3476,  3.2867,  0.7634]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Attention\n",
        "\n",
        "def random_tensors(shape, num=1, requires_grad=False):\n",
        "  tensors = [torch.randn(shape, requires_grad=requires_grad) for i in range(0, num)]\n",
        "  return tensors[0] if num == 1 else tensors\n",
        "\n",
        "# Parameters\n",
        "# [hidden_dimension]\n",
        "bM, br, w = random_tensors([7], num=3, requires_grad=True)\n",
        "# [hidden_dimension x hidden_dimension]\n",
        "WY, Wh, Wr, Wt = random_tensors([7, 7], num=4, requires_grad=True)\n",
        "\n",
        "def attention(Y, ht, rt1):\n",
        "  # [batch_size x hidden_dimension] \n",
        "  tmp = torch.einsum('ik, kl -> il', [ht, Wh]) + torch.einsum('ik, kl -> il', [rt1, Wr])\n",
        "\n",
        "  Mt = torch.tanh(torch.einsum('ijk, kl -> ijl', [Y, WY]) + tmp.unsqueeze(1).expand_as(Y) + bM)\n",
        "  \n",
        "  # [batch_size x sequence_length]\n",
        "  at = torch.nn.functional.softmax(torch.einsum('ijk, k -> ij', [Mt, w])) \n",
        "  \n",
        "  # [batch_size x hidden_dimension]\n",
        "  rt = torch.einsum('ijk, ij -> ik', [Y, at]) + torch.tanh(torch.einsum('ij, jk -> ik', [rt1, Wt]) + br)\n",
        "  \n",
        "  return rt, at\n",
        "\n",
        "# Inputs - [batch_size x sequence_length x hidden_dimension]\n",
        "Y = torch.randn(3,5,7)\n",
        "# [batch_size x hidden_dimension]\n",
        "ht, rt1 = random_tensors([3, 7], num=2)\n",
        "\n",
        "rt, at = attention(Y, ht, rt1)\n",
        "\n",
        "print(at)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V1hndqmL9Mi-",
        "outputId": "ec2cac25-1850-43f4-ceae-a89754c63771"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.0647, 0.2903, 0.2387, 0.1789, 0.2274],\n",
            "        [0.2058, 0.2523, 0.1002, 0.3406, 0.1010],\n",
            "        [0.2283, 0.1497, 0.1871, 0.2983, 0.1366]], grad_fn=<SoftmaxBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-14-0f495568e4dc>:20: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  at = torch.nn.functional.softmax(torch.einsum('ijk, k -> ij', [Mt, w]))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Treeqn\n",
        "\n",
        "def transition(zl):\n",
        "  # [batch_size x num_actions x hidden_dimension]\n",
        "  return zl.unsqueeze(1) + torch.tanh(torch.einsum('bk, aki -> bai', [zl, W]) + b)\n",
        "\n",
        "# Inputs - [batch_size x hidden_dimension]\n",
        "zl = torch.randn(2, 3)\n",
        "# Parameters - [num_actions x hidden_dimension]\n",
        "b = torch.randn(5, 3)\n",
        "# Actions - [num_actions x hidden_dimension x hidden_dimension]\n",
        "W = torch.randn(5, 3, 3)\n",
        "\n",
        "transition(zl)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xmqtU8_B9PkR",
        "outputId": "2408a889-614e-4d64-fbbd-23b063936ec2"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[ 1.1293, -2.3820,  2.1949],\n",
              "         [ 0.0228, -0.7951,  2.3060],\n",
              "         [ 1.0738, -0.5156,  0.3137],\n",
              "         [-0.7932, -2.3968,  2.2596],\n",
              "         [ 1.1106, -0.4044,  2.3088]],\n",
              "\n",
              "        [[ 0.0533,  0.2774,  0.0065],\n",
              "         [-0.6033, -0.3555,  0.2179],\n",
              "         [ 0.7827, -0.5702,  0.2113],\n",
              "         [ 0.7182, -0.3978,  0.3556],\n",
              "         [-0.1743, -0.0963, -0.2351]]])"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    }
  ]
}